{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.90.26:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.classification import NaiveBayes, SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from urllib.parse import unquote\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating RDDs\n",
    "good = sc.textFile(\"goodqueries.txt\").map(lambda line: unquote(line)).distinct()\n",
    "bad = sc.textFile(\"badqueries.txt\").map(lambda line: unquote(line)).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1310506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Amount of entries')\n",
    "good.count()+bad.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "## Feature extarcting\n",
    "models can't evaluate string so we will want to turn the string into numerical vectors using the HashingTF and IDF provided by spark. First of all, words won't helps in http queries so we will turn each query into bigrams to exapnad the and treating each by gram as a word. This approach will expand the word bucket and the feature space.An Example for bigram is given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE: bigram of the word <script>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s', 'sc', 'cr', 'ri', 'ip', 'pt', 't>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_ngram(payload_obj,n=1):\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-n+1):\n",
    "        ngrams.append(payload[i:i+n])\n",
    "    return ngrams\n",
    "\n",
    "print('EXAMPLE: bigram of the word <script>:')\n",
    "to_ngram(\"<script>\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 #bigram\n",
    "good_ngrams = good.map(lambda query: to_ngram(query,n))\n",
    "bad_ngrams = bad.map(lambda query: to_ngram(query,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hashing each query into 2,000 word bucket.\n",
    "As you can see, each query is turned into a sparse vector holding bucket numbers and occurrences this vector will be used as a feature vector input for our models\n",
    "###### pyspark mllib models needs LabeledPoint as an input \n",
    "So, the next step is to label our features: 1 for bad query, 0 for good query. The result is a collected of labeled samples which are ready for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = 2000\n",
    "hashingTF = HashingTF(numFeatures = numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature vector: ((2000,[104,136,201,744,1289,1511,1556,1683],[0.7005679684456778,1.1262072621936845,1.2943791186220295,0.6910471473539014,1.2513543383584065,0.014944590529120573,0.868974984310208,0.9827909772435368]),0.0)\n"
     ]
    }
   ],
   "source": [
    "# Hashing\n",
    "good_tf = hashingTF.transform(good)\n",
    "bad_tf = hashingTF.transform(bad)\n",
    "\n",
    "good_tf.cache()\n",
    "bad_tf.cache()\n",
    "\n",
    "# get TF-IDF\n",
    "idf = IDF().fit(good_tf.union(bad_tf))\n",
    "good_tfidf = idf.transform(good_tf).map(lambda x: LabeledPoint(0.0, x))\n",
    "bad_tfidf = idf.transform(bad_tf).map(lambda x: LabeledPoint(1.0, x))\n",
    "\n",
    "good_tfidf.cache()\n",
    "bad_tfidf.cache()\n",
    "hashingTF.cache()\n",
    "idf.cache()\n",
    "\n",
    "example_input = good_tfidf.take(1)[0]\n",
    "print(f'feature vector: ({example_input.features},{example_input.label})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Evaluate\n",
    "### Selected models:\n",
    " 1. NaiveBayes\n",
    " 2. LogisticRegression\n",
    " 3. SVM\n",
    " 4. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into train set and test set\n",
    "[training_data, test_data] = good_tfidf.union(bad_tfidf).randomSplit([0.8, 0.2])\n",
    "training_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "#helper functions:\n",
    "\n",
    "def evaluate(name,model,test_data,params=None):\n",
    "    labels = test_data.map(lambda d: d.label)\n",
    "    features = test_data.map(lambda d: d.features)\n",
    "    predictions = model.predict(features).map(lambda x: float(x))\n",
    "    predictionsAndLabels = predictions.zip(labels)\n",
    "        \n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "    accuracy = metrics.accuracy\n",
    "    \n",
    "    print(name) \n",
    "    if params is not None:\n",
    "        print(f'parmas: [\\n{params}\\n]\\n')      \n",
    "    print('summary:')\n",
    "    print(f'\\nPrecision = {precision}\\nRecall = {recall}\\nF1 Score = {f1Score}\\nAccuracy = {accuracy}\\n')\n",
    "    print('Confusion Matrix:\\n')\n",
    "    print(metrics.confusionMatrix().toArray())\n",
    "    \n",
    "\n",
    "def save_model(path, model):\n",
    "    model.save(sc, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "parmas: [\n",
      "lambda_=1.0\n",
      "]\n",
      "\n",
      "summary:\n",
      "\n",
      "Precision = 0.9868989817506583\n",
      "Recall = 0.9868989817506583\n",
      "F1 Score = 0.9868989817506583\n",
      "Accuracy = 0.9868989817506583\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[252644.   1158.]\n",
      " [  2285.   6717.]]\n"
     ]
    }
   ],
   "source": [
    "name = \"Naive Bayes Classifier\"\n",
    "params = 'lambda_=1.0'\n",
    "nvc = NaiveBayes.train(training_data)\n",
    "evaluate(name, nvc, test_data, params=params.replace(\",\",\"\\n\"))\n",
    "save_model('./models/' + name.replace(\" \",\"_\"), nvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "parmas: [\n",
      "iterations=100\n",
      " initialWeights=None\n",
      " regParam=0.001\n",
      " regType='l2'\n",
      " intercept=False\n",
      " corrections=10\n",
      " tolerance=1e-06\n",
      " validateData=True\n",
      " numClasses=2\n",
      "]\n",
      "\n",
      "summary:\n",
      "\n",
      "Precision = 0.9896843274835999\n",
      "Recall = 0.9896843274835999\n",
      "F1 Score = 0.9896843274835999\n",
      "Accuracy = 0.9896843274835999\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[253097.    705.]\n",
      " [  2006.   6996.]]\n"
     ]
    }
   ],
   "source": [
    "name = 'Logistic Regression'\n",
    "params = \"iterations=100, initialWeights=None, regParam=0.001, regType='l2', intercept=False, corrections=10, tolerance=1e-06, validateData=True, numClasses=2\"\n",
    "\n",
    "logreg = LogisticRegressionWithLBFGS.train(training_data,regParam=0.001)\n",
    "\n",
    "evaluate(name, logreg, test_data, params=params.replace(\",\",\"\\n\"))\n",
    "save_model('./models/' + name.replace(\" \",\"_\"), logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model\n",
      "parmas: [\n",
      "iterations=100\n",
      "step=1.0\n",
      "regParam=0.01\n",
      "miniBatchFraction=1.0\n",
      "initialWeights=None\n",
      "regType='l2'\n",
      "intercept=False\n",
      "validateData=True\n",
      "convergenceTol=0.001\n",
      "]\n",
      "\n",
      "summary:\n",
      "\n",
      "Precision = 0.9892124929605334\n",
      "Recall = 0.9892124929605334\n",
      "F1 Score = 0.9892124929605334\n",
      "Accuracy = 0.9892124929605334\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[253289.    513.]\n",
      " [  2322.   6680.]]\n"
     ]
    }
   ],
   "source": [
    "name = 'SVM Model'\n",
    "params = \"iterations=100,step=1.0,regParam=0.01,miniBatchFraction=1.0,initialWeights=None,regType='l2',intercept=False,validateData=True,convergenceTol=0.001\"\n",
    "svm = SVMWithSGD.train(training_data, iterations=100)\n",
    "evaluate(name, svm, test_data, params=params.replace(\",\",\"\\n\"))\n",
    "save_model('./models/' + name.replace(\" \",\"_\"), svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "parmas: [\n",
      "numClasses=2\n",
      " categoricalFeaturesInfo={}\n",
      "numTrees=60\n",
      " featureSubsetStrategy='auto'\n",
      "impurity='gini'\n",
      " maxDepth=30\n",
      " maxBins=32\n",
      "]\n",
      "\n",
      "summary:\n",
      "\n",
      "Precision = 0.9823753681310737\n",
      "Recall = 0.9823753681310737\n",
      "F1 Score = 0.9823753681310737\n",
      "Accuracy = 0.9823753681310737\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[254059.      0.]\n",
      " [  4632.   4123.]]\n"
     ]
    }
   ],
   "source": [
    "name = 'Random Forest'\n",
    "params = \"numClasses=2, categoricalFeaturesInfo={},numTrees=60, featureSubsetStrategy='auto',impurity='gini', maxDepth=30, maxBins=32\"\n",
    "\n",
    "rf = RandomForest.trainClassifier(\n",
    "    training_data,\n",
    "    numClasses=2,\n",
    "    categoricalFeaturesInfo={},\n",
    "    numTrees=60, \n",
    "    featureSubsetStrategy=\"auto\",\n",
    "    impurity='gini',\n",
    "    maxDepth=30,\n",
    "    maxBins=32\n",
    ")\n",
    "\n",
    "evaluate(name, rf, test_data, params=params.replace(\",\",\"\\n\"),isTree=True)\n",
    "save_model('./models/' + name.replace(\" \",\"_\"), rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(idf.transform(hashingTF.transform('<script>alert()</script>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(idf.transform(hashingTF.transform('ricky')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./vectorizers/hashingTF.pickle', 'wb') as f:\n",
    "    pickle.dump(hashingTF, f)\n",
    "    \n",
    "#//TODO : Save idf model    \n",
    "# with open('./vectorizers/IDF.pickle', 'wb') as f:\n",
    "#     pickle.dump(idf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load\n",
    "with open('./vectorizers/hashingTF.pickle', 'rb') as f:\n",
    "    new_tf = pickle.load(f)\n",
    "    \n",
    "# with open('./vectorizers/IDF.pickle', 'rb') as f:\n",
    "#     new_idf = pickle.load(f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(idf.transform(new_tf.transform('<script>alert()</script>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
