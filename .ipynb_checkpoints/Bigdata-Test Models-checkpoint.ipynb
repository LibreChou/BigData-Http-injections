{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0L0-NUF58S7"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/ec2-user/spark-2.4.5-bin-hadoop2.7')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpjydvmV6Y2X"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import CountVectorizerModel, IDFModel, StandardScalerModel, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35275,
     "status": "ok",
     "timestamp": 1587391879616,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "P8FC3v5C6cYr",
    "outputId": "f6d03f0b-fd1b-4626-de52-e8aaa3606ba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-83-21.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigData</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=BigData>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APP_NAME = \"BigData\"\n",
    "conf = pyspark.SparkConf().setAll([ ('spark.app.name', APP_NAME),('spark.executor.memory', '8g'), ('spark.cores.max', '2'), ('spark.driver.memory','8g')])\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlc = SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeSdu50C6lzS"
   },
   "outputs": [],
   "source": [
    "def to_ngram(payload_obj):\n",
    "    n=2\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = ''\n",
    "    for i in range(0,len(payload)-n + 1):\n",
    "        ngrams += payload[i:i+n]+ ' '\n",
    "    return ngrams[:-1]\n",
    "\n",
    "ngrams = udf(to_ngram, StringType())\n",
    "tokenizer = Tokenizer.load('models/Tokenizer')\n",
    "vectorizer = CountVectorizerModel.load('models/Vectorizer')\n",
    "idf_model = IDFModel.load('models/idf')\n",
    "scalerModel = StandardScalerModel.load('models/scalerModel')\n",
    "model = LogisticRegressionModel.load('models/Logistic_Regression_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnEoIVoP7PIJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1587393178396,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "zA5mnntB6gCe",
    "outputId": "d2029472-c4aa-416f-fd20-d5eaf2e8542e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             payload|      scaledFeatures|\n",
      "+--------------------+--------------------+\n",
      "|               Alice|(4472,[34,42,53,1...|\n",
      "|             bigdata|(4472,[24,43,169,...|\n",
      "|           hellworld|(4472,[23,75,86,9...|\n",
      "|select* from stud...|(4472,[0,13,17,19...|\n",
      "|<sctipt>alert('ha...|(4472,[3,6,7,13,2...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = sc.parallelize(['Alice','bigdata',\"hellworld\",\"select* from students where '1'='1\",\"<sctipt>alert('hacked');</sctipt>\"]).map(lambda q: Row(payload=q))\n",
    "sample_df = sqlc.createDataFrame(queries)\n",
    "\n",
    "sample_df = sample_df.withColumn('ngrams', ngrams(sample_df['payload']))\n",
    "sample_df = tokenizer.transform(sample_df)\n",
    "sample_df = vectorizer.transform(sample_df)\n",
    "sample_df = idf_model.transform(sample_df)\n",
    "sample_df = scalerModel.transform(sample_df).cache()\n",
    "preds = model.transform(sample_df)\n",
    "sample_df.select('payload','scaledFeatures').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1587393178689,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "Em1kdrIc9Htq",
    "outputId": "c8fa015e-04ef-468f-e6aa-524650c74ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------+\n",
      "|payload                           |prediction|\n",
      "+----------------------------------+----------+\n",
      "|Alice                             |0.0       |\n",
      "|bigdata                           |0.0       |\n",
      "|hellworld                         |0.0       |\n",
      "|select* from students where '1'='1|1.0       |\n",
      "|<sctipt>alert('hacked');</sctipt> |1.0       |\n",
      "+----------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.transform(sample_df)\n",
    "preds.select('payload','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acfu-oqE9c3y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockRDD[58] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[59] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[60] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[61] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[62] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[63] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[64] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[65] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[66] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[67] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[68] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[69] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[70] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[71] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[72] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[73] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[74] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[75] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[76] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[77] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[78] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[79] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[80] at socketTextStream at NativeMethodAccessorImpl.java:0\n",
      "No data\n",
      "BlockRDD[81] at socketTextStream at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "def to_ngram(payload_obj):\n",
    "    n=2\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = ''\n",
    "    for i in range(0,len(payload)-n + 1):\n",
    "        ngrams += payload[i:i+n]+ ' '\n",
    "    return ngrams[:-1]\n",
    "\n",
    "ngrams = udf(to_ngram, StringType())\n",
    "\n",
    "# define a function to compute sentiments of the received tweets\n",
    "def get_prediction(queries):\n",
    "    print(queries)\n",
    "    try:\n",
    "        queries = queries.map(lambda w: Row(payload=w))\n",
    "        queries = sqlc.createDataFrame(queries)\n",
    "        print(queries)\n",
    "        queries = queries.withColumn('ngrams', ngrams(queries['payload']))\n",
    "        queries = tokenizer.transform(queries)\n",
    "        queries = vectorizer.transform(queries)\n",
    "        queries = idf_model.transform(queries)\n",
    "        queries = scalerModel.transform(queries)\n",
    "        preds = model.transform(queries)\n",
    "        preds.select('payload','prediction').show()\n",
    "    except : \n",
    "        print('No data')\n",
    "    \n",
    "\n",
    "ssc = StreamingContext(sc, batchDuration= 3)\n",
    "lines = ssc.socketTextStream(\"ec2-52-90-109-113.compute-1.amazonaws.com\", 9999)\n",
    "\n",
    "lines.foreachRDD(get_prediction)\n",
    "\n",
    "ssc.start()             \n",
    "\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpkNEUnkxB7OS4D1ldzXzv",
   "mount_file_id": "1ZBJ5Vq--nZuHZew3qK5jR-cQcr2K0f_E",
   "name": "Bigdata-Test Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
