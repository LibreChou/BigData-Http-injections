{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0L0-NUF58S7"
   },
   "outputs": [],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !rm spark-2.4.5-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# # path variables\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "# find pyspark library\n",
    "import findspark\n",
    "findspark.init('/usr/local/spark/spark-2.4.0-bin-hadoop2.7/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpjydvmV6Y2X"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import CountVectorizerModel, IDFModel, StandardScalerModel, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35275,
     "status": "ok",
     "timestamp": 1587391879616,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "P8FC3v5C6cYr",
    "outputId": "f6d03f0b-fd1b-4626-de52-e8aaa3606ba8"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"BigData\"\n",
    "conf = pyspark.SparkConf().setAll([ ('spark.app.name', APP_NAME),('spark.executor.memory', '8g'), ('spark.cores.max', '2'), ('spark.driver.memory','8g')])\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlc = SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeSdu50C6lzS"
   },
   "outputs": [],
   "source": [
    "def to_ngram(payload_obj):\n",
    "    n=2\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = ''\n",
    "    for i in range(0,len(payload)-n + 1):\n",
    "        ngrams += payload[i:i+n]+ ' '\n",
    "    return ngrams[:-1]\n",
    "\n",
    "ngrams = udf(to_ngram, StringType())\n",
    "tokenizer = Tokenizer.load('models/Tokenizer')\n",
    "vectorizer = CountVectorizerModel.load('models/Vectorizer')\n",
    "idf_model = IDFModel.load('models/idf')\n",
    "scalerModel = StandardScalerModel.load('models/scalerModel')\n",
    "model = LogisticRegressionModel.load('models/Logistic_Regression_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnEoIVoP7PIJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1587393178396,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "zA5mnntB6gCe",
    "outputId": "d2029472-c4aa-416f-fd20-d5eaf2e8542e"
   },
   "outputs": [],
   "source": [
    "queries = sc.parallelize(['Alice','bigdata',\"hellworld\",\"select* from students where '1'='1\",\"<sctipt>alert('hacked');</sctipt>\"]).map(lambda q: Row(payload=q))\n",
    "sample_df = sqlc.createDataFrame(queries)\n",
    "\n",
    "sample_df = sample_df.withColumn('ngrams', ngrams(sample_df['payload']))\n",
    "sample_df = tokenizer.transform(sample_df)\n",
    "sample_df = vectorizer.transform(sample_df)\n",
    "sample_df = idf_model.transform(sample_df)\n",
    "sample_df = scalerModel.transform(sample_df).cache()\n",
    "preds = model.transform(sample_df)\n",
    "sample_df.select('payload','scaledFeatures').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1587393178689,
     "user": {
      "displayName": "Ricky Danipog",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjdVSCcL1RoxFc5DK1ncBF_pUSkI51Xu7pKoBB6Iw=s64",
      "userId": "04642021946591219207"
     },
     "user_tz": -180
    },
    "id": "Em1kdrIc9Htq",
    "outputId": "c8fa015e-04ef-468f-e6aa-524650c74ff5"
   },
   "outputs": [],
   "source": [
    "preds = model.transform(sample_df)\n",
    "preds.select('payload','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acfu-oqE9c3y"
   },
   "outputs": [],
   "source": [
    "def to_ngram(payload_obj):\n",
    "    n=2\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = ''\n",
    "    for i in range(0,len(payload)-n + 1):\n",
    "        ngrams += payload[i:i+n]+ ' '\n",
    "    return ngrams[:-1]\n",
    "\n",
    "ngrams = udf(to_ngram, StringType())\n",
    "\n",
    "# define a function to compute sentiments of the received tweets\n",
    "def get_prediction(queries):\n",
    "    try:\n",
    "        queries = queries.map(lambda w: Row(payload=w))\n",
    "        queries = sqlc.createDataFrame(queries)\n",
    "\n",
    "        queries = queries.withColumn('ngrams', ngrams(queries['payload']))\n",
    "        queries = tokenizer.transform(queries)\n",
    "        queries = vectorizer.transform(queries)\n",
    "        queries = idf_model.transform(queries)\n",
    "        queries = scalerModel.transform(queries)\n",
    "        preds = model.transform(queries)\n",
    "        preds.select('payload','prediction').show()\n",
    "    except : \n",
    "        print('No data')\n",
    "    \n",
    "\n",
    "ssc = StreamingContext(sc, batchDuration= 3)\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "lines.foreachRDD(get_prediction)\n",
    "\n",
    "ssc.start()             \n",
    "\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpkNEUnkxB7OS4D1ldzXzv",
   "mount_file_id": "1ZBJ5Vq--nZuHZew3qK5jR-cQcr2K0f_E",
   "name": "Bigdata-Test Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
