{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.90.26:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkFiles\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionWithSGD\n",
    "from urllib.parse import unquote\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating RDDs\n",
    "good = sc.textFile(\"goodqueries.txt\").map(lambda line: unquote(line)).distinct()\n",
    "bad = sc.textFile(\"badqueries.txt\").map(lambda line: unquote(line)).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1310506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Amount of entries')\n",
    "good.count()+bad.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "## Feature extarcting\n",
    "models can't evaluate string so we will want to turn the string into numerical vectors using the HashinTF provided by spark.First of all, words won't helps in http queries so we will turn each query into bigrams to exapnad the and treating each by gram as a word. This approach will expand the word bucket and the feature space.An Example for bigram is given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE: bigram of the word <script>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s', 'sc', 'cr', 'ri', 'ip', 'pt', 't>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_ngram(payload_obj,n=1):\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-n+1):\n",
    "        ngrams.append(payload[i:i+n])\n",
    "    return ngrams\n",
    "\n",
    "print('EXAMPLE: bigram of the word <script>:')\n",
    "to_ngram(\"<script>\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 #bigram\n",
    "good_ngrams = good.map(lambda query: to_ngram(query,n))\n",
    "bad_ngrams = bad.map(lambda query: to_ngram(query,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### hashing each query into 1,000 word bucket.\n",
    "As you can see, each query is turned into a sparse vector holding bucket numbers and occurrences this vector will be used as a feature vecctor input for our models\n",
    "###### pyspark mllib models needs LabeledPoint as an input \n",
    "So, the next step is to label our features: 1 for bad query, 0 for good query. The result is a collected of labeled samples which are ready for use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = 2000\n",
    "hahsingTF = HashingTF(numFeatures = numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature vector: ((2000,[104,136,201,744,1289,1511,1556,1683],[0.7005679684456778,1.1262072621936845,1.2943791186220295,0.6910471473539014,1.2513543383584065,0.014944590529120573,0.868974984310208,0.9827909772435368]),0.0)\n"
     ]
    }
   ],
   "source": [
    "good_tf = hahsingTF.transform(good)\n",
    "bad_tf = hahsingTF.transform(bad)\n",
    "\n",
    "good_tf.cache()\n",
    "bad_tf.cache()\n",
    "\n",
    "idf = IDF().fit(good_tf.union(bad_tf))\n",
    "good_tfidf = idf.transform(good_tf).map(lambda x: LabeledPoint(0.0, x))\n",
    "bad_tfidf = idf.transform(bad_tf).map(lambda x: LabeledPoint(1.0, x))\n",
    "\n",
    "example_input = good_tfidf.take(1)[0]\n",
    "print(f'feature vector: ({example_input.features},{example_input.label})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "[training_data, test_data] = good_tfidf.union(bad_tfidf).randomSplit([0.8, 0.2])\n",
    "training_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "\n",
    "def evaluate_accuracy(model):\n",
    "    predictions = model.predict(test_data.map(lambda x: x.features))\n",
    "    labels_and_preds = test_data.map(lambda x: x.label).zip(predictions)\n",
    "    accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data.count())\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875050505820557"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes   \n",
    "\n",
    "model = NaiveBayes.train(training_data)\n",
    "evaluate_accuracy(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(idf.transform(hahsingTF.transform('hi')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(idf.transform(hahsingTF.transform('ricky')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(idf.transform(hahsingTF.transform('yuval motek')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(idf.transform(hahsingTF.transform('stuff=\\'uname >q36497765 #')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.feature import HashingTF, IDF\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "# from pyspark.mllib.classification import NaiveBayes   \n",
    "\n",
    "# training_raw = sc.parallelize([\n",
    "#     {\"text\": \"foo foo foo bar bar protein\", \"label\": 1.0},\n",
    "#     {\"text\": \"foo bar dna for bar\", \"label\": 0.0},\n",
    "#     {\"text\": \"foo bar foo dna foo\", \"label\": 0.0},\n",
    "#     {\"text\": \"bar foo protein foo \", \"label\": 1.0}])\n",
    "\n",
    "\n",
    "# # Split data into labels and features, transform\n",
    "# # preservesPartitioning is not really required\n",
    "# # since map without partitioner shouldn't trigger repartitiong\n",
    "# labels = training_raw.map(\n",
    "#     lambda doc: doc[\"label\"],  # Standard Python dict access \n",
    "#     preservesPartitioning=True # This is obsolete.\n",
    "# )\n",
    "\n",
    "# tf = HashingTF(numFeatures=100).transform( ## Use much larger number in practice\n",
    "#     training_raw.map(lambda doc: doc[\"text\"].split(), \n",
    "#     preservesPartitioning=True))\n",
    "\n",
    "# idf = IDF().fit(tf)\n",
    "# tfidf = idf.transform(tf)\n",
    "\n",
    "# # Combine using zip\n",
    "# training = labels.zip(tfidf).map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "# # Train and check\n",
    "# model = NaiveBayes.train(training)\n",
    "# labels_and_preds = labels.zip(model.predict(tfidf)).map(\n",
    "#     lambda x: {\"actual\": x[0], \"predicted\": float(x[1])})\n",
    "\n",
    "\n",
    "# from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# from operator import itemgetter\n",
    "\n",
    "# metrics = MulticlassMetrics(\n",
    "#     labels_and_preds.map(itemgetter(\"actual\", \"predicted\")))\n",
    "\n",
    "# metrics.confusionMatrix().toArray()\n",
    "# ## array([[ 2.,  0.],\n",
    "# ##        [ 0.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabeledPoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
